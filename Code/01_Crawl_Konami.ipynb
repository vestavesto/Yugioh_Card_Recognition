{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "import os\n",
    "import urllib\n",
    "import tqdm\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "XPATH = \"xpath\"\n",
    "erwo = \"*error\"\n",
    "dash = '-'\n",
    "slash = '/'\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general settings\n",
    "url_main = \"https://decklist.tistory.com/\"\n",
    "xp_title = '//*[@id=\"container\"]/main/div/div[2]/div[1]/div/div/h2'\n",
    "xp_man = '//*[@id=\"container\"]/main/div/div[2]/div[2]/div[2]/table/tbody/tr[1]/td[2]'\n",
    "\n",
    "# Create headless ChromeOptions object\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "# Create a new ChromeDriverService object with the path to the Chromedriver executable\n",
    "service = Service('C://chromedriver.exe')\n",
    "\n",
    "# Initialize Chrome driver with headless options\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KONAMI DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = 7978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=en'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name = '//*[@id=\"cardname\"]/h1'\n",
    "xpath_pull = '//*[@id=\"update_list\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name_all = driver.find_element(By.XPATH, xpath_name)\n",
    "dt_name_all=dt_name_all.text\n",
    "dt_name_all.split(\"\\n\")\n",
    "print(dt_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "dt_pull = dt_pull.text\n",
    "\n",
    "# dt_pull_j = \"\".join(dt_pull)\n",
    "dt_pull_s = dt_pull.split(\"\\n\")\n",
    "dt_pull_s.pop(0)\n",
    "print(len(dt_pull_s))\n",
    "print(dt_pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = re.compile('[0-9]{4}.[0-9]{2}.[0-9]{2}')\n",
    "p2 = re.compile(r'^[A-Z0-9]+(?:-[A-Z0-9]+)*$')\n",
    "\n",
    "rare = [\n",
    "    'CR',\n",
    "    'SE', 'EXSE', 'PSE',\n",
    "    'GUR', 'GSE', 'GR',\n",
    "    'HR','GH',\n",
    "    'UR (PR)','PGR',\n",
    "    'KC', 'KC+R','KC+UR',\n",
    "    'M', 'M+GR', 'M+SE', 'M+SR',\n",
    "    'N','R','SR',\n",
    "    'UR','UL',\n",
    "    'P','P+ES','P+EXSE','P+HR','P+R','PS','P+SE','P+SR','P+UR',\n",
    "    '20th SE', 'QCSE',\n",
    "    '10000 SE',\n",
    "    'SH','H','STAR','UR (Hobby)','ST', 'MR', 'PL',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_year=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p1,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_year.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pack=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p2,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_pack.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_capsule = []\n",
    "for year in check_year:\n",
    "    a = dt_pull_s[year]\n",
    "    try:\n",
    "        b = dt_pull_s[year+1]\n",
    "    except:\n",
    "        b = None\n",
    "    try:\n",
    "        c = dt_pull_s[year+2]\n",
    "    except:\n",
    "        c = None\n",
    "    try:\n",
    "        d = dt_pull_s[year+3]\n",
    "    except:\n",
    "        d = None\n",
    "    db_capsule.append([ a,b,c,d ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame (db_capsule, columns = [\"Year\",\"Code\",\"Pack\",\"Rarity\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "for item in check_year:\n",
    "    da = dt_pull_s[item]\n",
    "    try:\n",
    "        db = dt_pull_s[item+1]\n",
    "    except:\n",
    "        db = None\n",
    "    try:\n",
    "        dc = dt_pull_s[item+2]\n",
    "    except:\n",
    "        dc = None\n",
    "    try:\n",
    "        dd = dt_pull_s[item+3]\n",
    "    except:\n",
    "        dd = None\n",
    "    # Append Year\n",
    "    db_year.append(da)\n",
    "    # Append Pack\n",
    "    if db == None:\n",
    "        db = erwo\n",
    "    elif re.search(p2,db):\n",
    "        pass\n",
    "    else:\n",
    "        db = erwo\n",
    "    db_pack.append(db)\n",
    "    # Append Rarity\n",
    "    if dd == None :\n",
    "        k = \"N\"\n",
    "    elif re.search(p1,dd):\n",
    "        k = \"N\"\n",
    "    elif  len(dd) > len(dc):\n",
    "        if re.search(p1,dc):\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            k = dc\n",
    "    else :\n",
    "        if len(dd) > 8:\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dd\n",
    "    db_rare.append(k)\n",
    "\n",
    "    print(f\"Year : {str(da)} | Pack : {db} | Rarity : {str(k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "for i, item in enumerate(tt):\n",
    "    try:\n",
    "        da, db, dc, dd = dt_pull_s[item:item+4]\n",
    "    except ValueError:\n",
    "        da = db = dc = dd = None\n",
    "\n",
    "    db_year.append(da)\n",
    "\n",
    "    db = db if db and re.search(p2, db) else erwo\n",
    "    db_pack.append(db)\n",
    "\n",
    "    if not dd:\n",
    "        k = \"N\"\n",
    "    elif re.search(p1, dd):\n",
    "        k = \"N\"\n",
    "    elif len(dd) > 6 or (len(dc) > len(dd) and re.search(p1, dc)):\n",
    "        k = dc or \"N\"\n",
    "    else:\n",
    "        k = dd\n",
    "    db_rare.append(k)\n",
    "\n",
    "    print(f\"Year : {str(da)} | Pack : {db} | Rarity : {str(k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =[]\n",
    "\n",
    "numb2 = []\n",
    "numb2.append(str(numb))\n",
    "\n",
    "k.append(numb2)\n",
    "k.append(db_pack)\n",
    "k.append(db_rare)\n",
    "\n",
    "print(k)\n",
    "\n",
    "list2d = k\n",
    "merged = list(itertools.chain.from_iterable(list2d))\n",
    "\n",
    "print(merged)\n",
    "\n",
    "kk = \"\\t\".join(merged)\n",
    "\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카드 수록팩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/ML_YGO/Data/konami_code.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name = '//*[@id=\"cardname\"]/h1'\n",
    "# xpath_name_en = '//*[@id=\"cardname\"]/h1/span'\n",
    "\n",
    "xpath_pull = '//*[@id=\"update_list\"]'\n",
    "\n",
    "xpath_type = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[1]/span[2]'\n",
    "xpath_level = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[2]/span[2]'\n",
    "xpath_atk = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[1]/span[2]'\n",
    "xpath_def = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[2]/span[2]'\n",
    "xpath_spc = '//*[@id=\"CardTextSet\"]/div[1]/div[3]/div/p'\n",
    "xpath_year = '//*[@id=\"update_list\"]/div[2]/div/div/div[1]'\n",
    "\n",
    "p1 = re.compile('[0-9]{4}.[0-9]{2}.[0-9]{2}')\n",
    "p2 = re.compile(r'^[A-Z0-9]+(?:-[A-Z0-9]+)*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= 'JUMP-EN036'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=en'\n",
    "erwo = \"*Blank*\"\n",
    "\n",
    "nline1 = []\n",
    "nline2 = []\n",
    "nline3 = []\n",
    "nline4 = []\n",
    "\n",
    "for i in tqdm(range(0,12200)):\n",
    "    numb = lines[i]\n",
    "    link = link_f+str(numb) + link_b\n",
    "    driver.get(link)\n",
    "\n",
    "    try:\n",
    "        dt_name = driver.find_element(By.XPATH, xpath_name)\n",
    "        dt_name = dt_name.text\n",
    "        if \"\\n\" in dt_name:\n",
    "            dt_name_sp = dt_name.split(\"\\n\")\n",
    "            dt_name_A = dt_name_sp[0]\n",
    "            dt_name_B = dt_name_sp[1]\n",
    "\n",
    "    except:\n",
    "        dt_name_A = erwo\n",
    "        dt_name_B = erwo\n",
    "\n",
    "    dt_name_all=[]\n",
    "    dt_name_all.append(dt_name)\n",
    "    # dt_name_all.append(dt_name_A)\n",
    "    # dt_name_all.append(dt_name_B)\n",
    "\n",
    "\n",
    "    try:\n",
    "        dt_type = driver.find_element(By.XPATH, xpath_type).text\n",
    "    except:\n",
    "        dt_type = erwo\n",
    "\n",
    "    try:\n",
    "        dt_level = driver.find_element(By.XPATH, xpath_level).text\n",
    "    except:\n",
    "        dt_level = erwo\n",
    "    \n",
    "    try:\n",
    "        dt_atk = driver.find_element(By.XPATH, xpath_atk).text\n",
    "    except:\n",
    "        dt_atk = erwo\n",
    "\n",
    "    try:\n",
    "        dt_def = driver.find_element(By.XPATH, xpath_def).text\n",
    "    except:\n",
    "        dt_def = erwo\n",
    "\n",
    "    try:\n",
    "        dt_spc = driver.find_element(By.XPATH, xpath_spc).text\n",
    "    except:\n",
    "        dt_spc = erwo\n",
    "\n",
    "    db_stats = [dt_type, dt_level, dt_atk, dt_def, dt_spc]\n",
    "\n",
    "    try:\n",
    "        dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "        dt_pull = dt_pull.text\n",
    "    except:\n",
    "        dt_pull = erwo\n",
    "\n",
    "    dt_pull_s = dt_pull.split(\"\\n\")\n",
    "    dt_pull_s.pop(0)\n",
    "\n",
    "    check_year = [m for m, dt_temp in enumerate(dt_pull_s) if re.search(p1, dt_temp)]\n",
    "\n",
    "    db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "    # fill Normal to blank\n",
    "    for year in check_year:\n",
    "        da = dt_pull_s[year] #1st\n",
    "        try:\n",
    "            db = dt_pull_s[year+1] #2nd\n",
    "        except IndexError:\n",
    "            db = None\n",
    "        try:\n",
    "            dc = dt_pull_s[year+2] #3rd\n",
    "        except IndexError:\n",
    "            dc = None\n",
    "        try:\n",
    "            dd = dt_pull_s[year+3] #4th\n",
    "        except IndexError:\n",
    "            dd = None\n",
    "\n",
    "        # Append Year\n",
    "        db_year.append(da)\n",
    "\n",
    "        # Append Pack\n",
    "        if re.search(p2,db):\n",
    "            pass\n",
    "        else:\n",
    "            db = erwo\n",
    "        db_pack.append(db)\n",
    "\n",
    "        # Append Rarity\n",
    "        if dd == None :\n",
    "            k = \"N\"\n",
    "        elif re.search(p1,dd):\n",
    "            k = \"N\"\n",
    "        \n",
    "        elif  len(dd) > len(dc): # Override 4th to 3rd\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dc\n",
    "        \n",
    "        else :\n",
    "            if len(dd) > 10: # For jp 8\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                if re.search(p1,dc):\n",
    "                    k = \"N\"\n",
    "                else:\n",
    "                    k = dd\n",
    "        db_rare.append(k)\n",
    "\n",
    "    k1 = []\n",
    "    k2 = []\n",
    "    k3 = []\n",
    "    k4 = []\n",
    "    numb2 = []\n",
    "    numb2.append(str(numb))\n",
    "    \n",
    "    k1.append(numb2)\n",
    "    k1.append(dt_name_all)\n",
    "    k1.append(db_pack)\n",
    "\n",
    "    k2.append(numb2)\n",
    "    k2.append(dt_name_all)\n",
    "    k2.append(db_rare)\n",
    "\n",
    "    k3.append(numb2)\n",
    "    k3.append(dt_name_all)\n",
    "    k3.append(db_stats)\n",
    "\n",
    "    k4.append(numb2)\n",
    "    k4.append(dt_name_all)\n",
    "    k4.append(db_year)\n",
    "\n",
    "    merged1 = list(itertools.chain.from_iterable(k1))\n",
    "    merged2 = list(itertools.chain.from_iterable(k2))\n",
    "    merged3 = list(itertools.chain.from_iterable(k3))\n",
    "    merged4 = list(itertools.chain.from_iterable(k4))\n",
    "\n",
    "    data1 = \"\\t\".join(merged1)\n",
    "    data2 = \"\\t\".join(merged2)\n",
    "    data3 = \"\\t\".join(merged3)\n",
    "    data4 = \"\\t\".join(merged4)\n",
    "\n",
    "    # numb2 = str(numb)\n",
    "    # data1 = '\\t'.join([numb2, dt_name_all, db_pack])\n",
    "    # data2 = '\\t'.join([numb2, dt_name_all, db_rare])\n",
    "    # data3 = '\\t'.join([numb2, dt_name_all] + db_stats)\n",
    "    # data4 = '\\t'.join([numb2, dt_name_all] + db_year)\n",
    "    \n",
    "    # append the data\n",
    "    nline1.append(data1)\n",
    "    nline2.append(data2)\n",
    "    nline3.append(data3)\n",
    "    nline4.append(data4)\n",
    "\n",
    "\n",
    "master = 'C:/ML_YGO/Output/'\n",
    "f1 = master + 'out_pa.txt'\n",
    "f2 = master + 'out_ra.txt'\n",
    "f3 = master + 'out_st.txt'\n",
    "f4 = master + 'out_yr.txt'\n",
    "\n",
    "with open(f1, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline1:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f2, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline2:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f3, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline3:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f4, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "os.startfile(f1)\n",
    "os.startfile(f2)\n",
    "os.startfile(f3)\n",
    "os.startfile(f4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_full_db = 'C:/ML_YGO/Data/rares.txt'\n",
    "df = pd.read_csv(dir_full_db, sep='\\t')\n",
    "# db_digit = np.asarray(df[\"Digit\"])\n",
    "# db_name_ko = np.asarray(df[\"Name_KO\"])\n",
    "# def fill_na_with_code(df):\n",
    "#     for col in df.columns:\n",
    "#         if col != 'Code' and df[col].isnull().any():\n",
    "#             df[col].fillna(df['Code'], inplace=True)\n",
    "#     return df\n",
    "# fill_na_with_code(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = pd.unique(df.values.ravel())\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "카드명 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link3 = '&request_locale=ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "xpath_name_en = '//*[@id=\"cardname\"]/h1/span'\n",
    "\n",
    "for i in range(0,54):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "    driver.get(link4)\n",
    "\n",
    "    try:\n",
    "        id = driver.find_element(By.XPATH, xpath_name_en)\n",
    "        idt = id.text\n",
    "        k = str(link2)\n",
    "        kk = k + \" - \" + idt\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korean Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=ko'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name_ja = '//*[@id=\"cardname\"]/h1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "dt_name=dt_name.text\n",
    "print(dt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_pack = '//*[@id=\"update_list\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pack = driver.find_element(By.XPATH, xpath_pack)\n",
    "dt_pack = dt_pack.text\n",
    "print(dt_pack)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Japanese Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=ja'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name_ja = '//*[@id=\"cardname\"]/h1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "dt_name=dt_name.text\n",
    "print(dt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "    driver.get(link4)\n",
    "\n",
    "    try:\n",
    "        id = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "        idt = id.text\n",
    "        m = idt.split(\"\\n\")\n",
    "        m = \"\\t\".join(m)\n",
    "        k = str(link2)\n",
    "        kk = k + \"\\t\" + m\n",
    "        print(kk)\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid=12950&request_locale=ja'\n",
    "req = requests.get(home)\n",
    "req.text\n",
    "soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = soup.find(\"div\", {\"id\": \"cardname\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = soup.find(\"div\", {\"id\": \"update_list\"}).text\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link3 = '&request_locale=ja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "\n",
    "    req = requests.get(link4)\n",
    "    req.text\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        b = soup.find(\"div\", {\"id\": \"cardname\"}).text\n",
    "        b1= b.replace(\"\\n\",\"\")\n",
    "        b2= b1.replace(\"\\t\\t\",\"\\t\")\n",
    "        b3= b2.replace(\"\\t\\t\",\"\\t\")\n",
    "        b4 = b3.split(\"\\t\")\n",
    "        b5 = \"\\t\".join(b4)\n",
    "        k = str(link2)\n",
    "        kk = k + \"\\t\" + b5\n",
    "        # print(kk)\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme_jp.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c50a568c9bb54733425ee4b50464281b54488c5e15ff27e4e32e073d46803f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
