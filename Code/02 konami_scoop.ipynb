{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "import os\n",
    "import urllib\n",
    "import tqdm\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "XPATH = \"xpath\"\n",
    "erwo = \"*error\"\n",
    "dash = '-'\n",
    "slash = '/'\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general settings\n",
    "url_main = \"https://decklist.tistory.com/\"\n",
    "xp_title = '//*[@id=\"container\"]/main/div/div[2]/div[1]/div/div/h2'\n",
    "xp_man = '//*[@id=\"container\"]/main/div/div[2]/div[2]/div[2]/table/tbody/tr[1]/td[2]'\n",
    "\n",
    "# Create headless ChromeOptions object\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "# Create a new ChromeDriverService object with the path to the Chromedriver executable\n",
    "service = Service('C://chromedriver.exe')\n",
    "\n",
    "# Initialize Chrome driver with headless options\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xp_deck_ind(ind):\n",
    "    return f'//*[@id=\"container\"]/main/div/div[2]/div[2]/div[2]/p[{ind}]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deck_info(driver, url_numb):\n",
    "    url_comb = url_main + str(url_numb)\n",
    "    driver.get(url_comb)\n",
    "\n",
    "    # Get title of the Game\n",
    "    try:\n",
    "        title_element = driver.find_element(By.XPATH, xp_title).text\n",
    "        game_cs = title_element.split(\"(\")[0].strip()\n",
    "        game_date = title_element.split(\")\")[1].strip()\n",
    "\n",
    "\n",
    "    except:\n",
    "        title_element = erwo\n",
    "        game_cs = erwo\n",
    "        game_date = erwo\n",
    "        logger.error(f'{url_numb} | Failed to get | Title info')    \n",
    "\n",
    "    \n",
    "\n",
    "    # Get Number of Players\n",
    "    try:\n",
    "        man_element = driver.find_element(By.XPATH, xp_man).text\n",
    "    except:\n",
    "        man_element = erwo\n",
    "        logger.error(f'{url_numb} | Failed to get | Man info')  \n",
    "\n",
    "    # Get Name of the Decks\n",
    "    deck_element_scrap = []\n",
    "    i = 1\n",
    "    while True:\n",
    "        try:\n",
    "            element = driver.find_element(By.XPATH, xp_deck_ind(i))\n",
    "            deck_element_scrap.append(element.text)\n",
    "            i += 1\n",
    "        except NoSuchElementException:\n",
    "            break\n",
    "\n",
    "    for i in range(len(deck_element_scrap)):\n",
    "        while '\\n' in deck_element_scrap[i]:\n",
    "            deck_element_scrap[i] = deck_element_scrap[i].replace('\\n', '')\n",
    "\n",
    "    # Modify Name of the Decks\n",
    "    deck_elements = (filter(lambda x: x != '', deck_element_scrap))\n",
    "    deck_elements = list(filter(lambda x: x != ' ', deck_elements))\n",
    "    # # deck_elements = [s.replace('\\n', '') for s in deck_elements]\n",
    "    # for i in range(len(deck_elements)):\n",
    "    #     while '\\n' in deck_elements[i]:\n",
    "    #         deck_elements[i] = deck_elements[i].replace('\\n', '')\n",
    "\n",
    "\n",
    "    deck_elements_dash = []\n",
    "    for deck in deck_elements:\n",
    "        if dash in deck:\n",
    "            deck = deck.split(dash)[1]\n",
    "        deck_elements_dash.append(deck)\n",
    "\n",
    "    deck_elements_slash = []\n",
    "    for deck in deck_elements_dash:\n",
    "        if slash in deck:\n",
    "            deck = deck.split(slash)\n",
    "            for d in deck:\n",
    "                deck_elements_slash.append(d)\n",
    "        else:\n",
    "            deck_elements_slash.append(deck)\n",
    "\n",
    "    deck_elements = [s.strip() for s in deck_elements_slash]\n",
    "    deck_elemetns_text = ' '.join(deck_element_scrap)\n",
    "\n",
    "    # Get the Images\n",
    "    img_elements = driver.find_elements(By.TAG_NAME, 'img')\n",
    "    db_comb = []\n",
    "    for i, img_element in enumerate(img_elements):\n",
    "        deck_code = f\"{url_numb:04d}-{i+1:03d}\"\n",
    "        filename = f\"C:\\ML_YGO\\Deck_Log\\{deck_code}.jpg\"\n",
    "        img_url = img_element.get_attribute('src')\n",
    "\n",
    "        # Skip GIF images\n",
    "        if img_url.startswith('data:image/gif'):\n",
    "            continue  \n",
    "\n",
    "        # Get the size of the images\n",
    "        response = requests.get(img_url)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        width, height = img.size\n",
    "\n",
    "        # Skip small images\n",
    "        if (width == 343 and height == 353) or width < 50:\n",
    "            pass\n",
    "        elif width > 0:\n",
    "            # Download Image\n",
    "            urllib.request.urlretrieve(img_url, filename)\n",
    "\n",
    "            if len(deck_elements) <= i:\n",
    "                deck_element = erwo\n",
    "            else:\n",
    "                deck_element = deck_elements[i]\n",
    "            \n",
    "            db_join = [  \n",
    "                deck_code,\n",
    "                game_cs,\n",
    "                game_date,\n",
    "                man_element, \n",
    "                deck_element,\n",
    "                title_element, \n",
    "                deck_elemetns_text\n",
    "            ]\n",
    "            db_comb.append(db_join)\n",
    "    return db_comb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run into Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5~594\n",
    "#600~1003\n",
    "#1004~1207\n",
    "#1317~1334\n",
    "#1334~1347\n",
    "#600~812 812~1003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "800 | Failed to get | Title info\n",
      "800 | Failed to get | Man info\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 | Running\n",
      "-- Waiting to cool down --\n",
      "801 | Running\n",
      "802 | Running\n",
      "803 | Running\n",
      "804 | Running\n",
      "805 | Running\n",
      "-- Waiting to cool down --\n",
      "806 | Running\n",
      "807 | Running\n",
      "808 | Running\n",
      "809 | Running\n",
      "810 | Running\n",
      "-- Waiting to cool down --\n",
      "811 | Running\n"
     ]
    }
   ],
   "source": [
    "master_comb =[]\n",
    "for i, url_numb in enumerate(range(800,812)):\n",
    "    print(f'{url_numb} | Running')\n",
    "    try: \n",
    "        db_comb = get_deck_info(driver,url_numb)\n",
    "    except:\n",
    "        print(f'{url_numb} | Unexpected Error')\n",
    "        break\n",
    "    master_comb.append(db_comb)\n",
    "    if i% 5 == 0:\n",
    "        time.sleep(2)\n",
    "        print(\"-- Waiting to cool down --\")\n",
    "\n",
    "master_comb_clean = []\n",
    "for first in master_comb:\n",
    "    for second in first:\n",
    "        joined_str = \"\\t\".join(second)\n",
    "        master_comb_clean.append (joined_str)\n",
    "\n",
    "dir_write = 'C:\\ML_YGO\\Output\\deck_stack.txt'\n",
    "open(dir_write, 'w').close()\n",
    "with open(dir_write , 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in master_comb_clean:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "os.startfile(dir_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_numb = 400\n",
    "url_comb = url_main + str(url_numb)\n",
    "driver.get(url_comb)\n",
    "\n",
    "# Get Name of the Decks\n",
    "deck_element_scrap = []\n",
    "i = 1\n",
    "while True:\n",
    "    try:\n",
    "        element = driver.find_element(By.XPATH, xp_deck_ind(i))\n",
    "        deck_element_scrap.append(element.text)\n",
    "        i += 1\n",
    "    except NoSuchElementException:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Modify Name of the Decks\n",
    "deck_elements = (filter(lambda x: x != '', deck_element_scrap))\n",
    "deck_elements = list(filter(lambda x: x != ' ', deck_elements))\n",
    "\n",
    "# deck_elements = [s.replace('\\n', '') for s in deck_elements]\n",
    "\n",
    "for i in range(len(deck_elements)):\n",
    "    while '\\n' in deck_elements[i]:\n",
    "        deck_elements[i] = deck_elements[i].replace('\\n', '')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(deck_element_scrap)\n",
    "\n",
    "print(deck_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legacy Code Save Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_element = driver.find_element(By.XPATH, xp_title)\n",
    "man_element = driver.find_element(By.XPATH, xp_man)\n",
    "img_elements = driver.find_elements(By.TAG_NAME, 'img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib\n",
    "\n",
    "XPATH = \"xpath\"\n",
    "TAG_NAME = \"tag_name\"\n",
    "\n",
    "# Create headless ChromeOptions object\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "# Initialize Chrome driver with headless options\n",
    "driver = webdriver.Chrome('C://cromedriver.exe', options=options)\n",
    "\n",
    "url_main = \"https://decklist.tistory.com/\"\n",
    "\n",
    "for i in range(1010, 1208):\n",
    "    url_numb = i\n",
    "    url_comb = url_main + str(url_numb)\n",
    "    driver.get(url_comb)\n",
    "\n",
    "    img_elements = driver.find_elements(By.TAG_NAME, 'img')\n",
    "\n",
    "    for i in range(len(img_elements)):\n",
    "        deck_code = f\"{url_numb:04d}-{i+1:03d}\"\n",
    "        filename = f\"C:\\ML_YGO\\Deck_Log\\{deck_code}.jpg\"\n",
    "        img_element = img_elements[i]\n",
    "        img_url = img_element.get_attribute('src')\n",
    "        urllib.request.urlretrieve(img_url, filename)\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KONAMI DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numb = 7978"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=en'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name = '//*[@id=\"cardname\"]/h1'\n",
    "xpath_pull = '//*[@id=\"update_list\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name_all = driver.find_element(By.XPATH, xpath_name)\n",
    "dt_name_all=dt_name_all.text\n",
    "dt_name_all.split(\"\\n\")\n",
    "print(dt_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "dt_pull = dt_pull.text\n",
    "\n",
    "# dt_pull_j = \"\".join(dt_pull)\n",
    "dt_pull_s = dt_pull.split(\"\\n\")\n",
    "dt_pull_s.pop(0)\n",
    "print(len(dt_pull_s))\n",
    "print(dt_pull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = re.compile('[0-9]{4}.[0-9]{2}.[0-9]{2}')\n",
    "p2 = re.compile(r'^[A-Z0-9]+(?:-[A-Z0-9]+)*$')\n",
    "\n",
    "rare = [\n",
    "    'CR',\n",
    "    'SE', 'EXSE', 'PSE',\n",
    "    'GUR', 'GSE', 'GR',\n",
    "    'HR','GH',\n",
    "    'UR (PR)','PGR',\n",
    "    'KC', 'KC+R','KC+UR',\n",
    "    'M', 'M+GR', 'M+SE', 'M+SR',\n",
    "    'N','R','SR',\n",
    "    'UR','UL',\n",
    "    'P','P+ES','P+EXSE','P+HR','P+R','PS','P+SE','P+SR','P+UR',\n",
    "    '20th SE', 'QCSE',\n",
    "    '10000 SE',\n",
    "    'SH','H','STAR','UR (Hobby)','ST', 'MR', 'PL',\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_year=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p1,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_year.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pack=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p2,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_pack.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_capsule = []\n",
    "for year in check_year:\n",
    "    a = dt_pull_s[year]\n",
    "    try:\n",
    "        b = dt_pull_s[year+1]\n",
    "    except:\n",
    "        b = None\n",
    "    try:\n",
    "        c = dt_pull_s[year+2]\n",
    "    except:\n",
    "        c = None\n",
    "    try:\n",
    "        d = dt_pull_s[year+3]\n",
    "    except:\n",
    "        d = None\n",
    "    db_capsule.append([ a,b,c,d ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame (db_capsule, columns = [\"Year\",\"Code\",\"Pack\",\"Rarity\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "for item in check_year:\n",
    "    da = dt_pull_s[item]\n",
    "    try:\n",
    "        db = dt_pull_s[item+1]\n",
    "    except:\n",
    "        db = None\n",
    "    try:\n",
    "        dc = dt_pull_s[item+2]\n",
    "    except:\n",
    "        dc = None\n",
    "    try:\n",
    "        dd = dt_pull_s[item+3]\n",
    "    except:\n",
    "        dd = None\n",
    "    # Append Year\n",
    "    db_year.append(da)\n",
    "    # Append Pack\n",
    "    if db == None:\n",
    "        db = erwo\n",
    "    elif re.search(p2,db):\n",
    "        pass\n",
    "    else:\n",
    "        db = erwo\n",
    "    db_pack.append(db)\n",
    "    # Append Rarity\n",
    "    if dd == None :\n",
    "        k = \"N\"\n",
    "    elif re.search(p1,dd):\n",
    "        k = \"N\"\n",
    "    elif  len(dd) > len(dc):\n",
    "        if re.search(p1,dc):\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            k = dc\n",
    "    else :\n",
    "        if len(dd) > 8:\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dd\n",
    "    db_rare.append(k)\n",
    "\n",
    "    print(f\"Year : {str(da)} | Pack : {db} | Rarity : {str(k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "for i, item in enumerate(tt):\n",
    "    try:\n",
    "        da, db, dc, dd = dt_pull_s[item:item+4]\n",
    "    except ValueError:\n",
    "        da = db = dc = dd = None\n",
    "\n",
    "    db_year.append(da)\n",
    "\n",
    "    db = db if db and re.search(p2, db) else erwo\n",
    "    db_pack.append(db)\n",
    "\n",
    "    if not dd:\n",
    "        k = \"N\"\n",
    "    elif re.search(p1, dd):\n",
    "        k = \"N\"\n",
    "    elif len(dd) > 6 or (len(dc) > len(dd) and re.search(p1, dc)):\n",
    "        k = dc or \"N\"\n",
    "    else:\n",
    "        k = dd\n",
    "    db_rare.append(k)\n",
    "\n",
    "    print(f\"Year : {str(da)} | Pack : {db} | Rarity : {str(k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k =[]\n",
    "\n",
    "numb2 = []\n",
    "numb2.append(str(numb))\n",
    "\n",
    "k.append(numb2)\n",
    "k.append(db_pack)\n",
    "k.append(db_rare)\n",
    "\n",
    "print(k)\n",
    "\n",
    "list2d = k\n",
    "merged = list(itertools.chain.from_iterable(list2d))\n",
    "\n",
    "print(merged)\n",
    "\n",
    "kk = \"\\t\".join(merged)\n",
    "\n",
    "print(kk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "카드 수록팩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'C:/ML_YGO/Data/konami_code.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name = '//*[@id=\"cardname\"]/h1'\n",
    "# xpath_name_en = '//*[@id=\"cardname\"]/h1/span'\n",
    "\n",
    "xpath_pull = '//*[@id=\"update_list\"]'\n",
    "\n",
    "xpath_type = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[1]/span[2]'\n",
    "xpath_level = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[2]/span[2]'\n",
    "xpath_atk = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[1]/span[2]'\n",
    "xpath_def = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[2]/span[2]'\n",
    "xpath_spc = '//*[@id=\"CardTextSet\"]/div[1]/div[3]/div/p'\n",
    "xpath_year = '//*[@id=\"update_list\"]/div[2]/div/div/div[1]'\n",
    "\n",
    "p1 = re.compile('[0-9]{4}.[0-9]{2}.[0-9]{2}')\n",
    "p2 = re.compile(r'^[A-Z0-9]+(?:-[A-Z0-9]+)*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= 'JUMP-EN036'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=en'\n",
    "erwo = \"*Blank*\"\n",
    "\n",
    "nline1 = []\n",
    "nline2 = []\n",
    "nline3 = []\n",
    "nline4 = []\n",
    "\n",
    "for i in tqdm(range(0,12200)):\n",
    "    numb = lines[i]\n",
    "    link = link_f+str(numb) + link_b\n",
    "    driver.get(link)\n",
    "\n",
    "    try:\n",
    "        dt_name = driver.find_element(By.XPATH, xpath_name)\n",
    "        dt_name = dt_name.text\n",
    "        if \"\\n\" in dt_name:\n",
    "            dt_name_sp = dt_name.split(\"\\n\")\n",
    "            dt_name_A = dt_name_sp[0]\n",
    "            dt_name_B = dt_name_sp[1]\n",
    "\n",
    "    except:\n",
    "        dt_name_A = erwo\n",
    "        dt_name_B = erwo\n",
    "\n",
    "    dt_name_all=[]\n",
    "    dt_name_all.append(dt_name)\n",
    "    # dt_name_all.append(dt_name_A)\n",
    "    # dt_name_all.append(dt_name_B)\n",
    "\n",
    "\n",
    "    try:\n",
    "        dt_type = driver.find_element(By.XPATH, xpath_type).text\n",
    "    except:\n",
    "        dt_type = erwo\n",
    "\n",
    "    try:\n",
    "        dt_level = driver.find_element(By.XPATH, xpath_level).text\n",
    "    except:\n",
    "        dt_level = erwo\n",
    "    \n",
    "    try:\n",
    "        dt_atk = driver.find_element(By.XPATH, xpath_atk).text\n",
    "    except:\n",
    "        dt_atk = erwo\n",
    "\n",
    "    try:\n",
    "        dt_def = driver.find_element(By.XPATH, xpath_def).text\n",
    "    except:\n",
    "        dt_def = erwo\n",
    "\n",
    "    try:\n",
    "        dt_spc = driver.find_element(By.XPATH, xpath_spc).text\n",
    "    except:\n",
    "        dt_spc = erwo\n",
    "\n",
    "    db_stats = [dt_type, dt_level, dt_atk, dt_def, dt_spc]\n",
    "\n",
    "    try:\n",
    "        dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "        dt_pull = dt_pull.text\n",
    "    except:\n",
    "        dt_pull = erwo\n",
    "\n",
    "    dt_pull_s = dt_pull.split(\"\\n\")\n",
    "    dt_pull_s.pop(0)\n",
    "\n",
    "    check_year = [m for m, dt_temp in enumerate(dt_pull_s) if re.search(p1, dt_temp)]\n",
    "\n",
    "    db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "    # fill Normal to blank\n",
    "    for year in check_year:\n",
    "        da = dt_pull_s[year] #1st\n",
    "        try:\n",
    "            db = dt_pull_s[year+1] #2nd\n",
    "        except IndexError:\n",
    "            db = None\n",
    "        try:\n",
    "            dc = dt_pull_s[year+2] #3rd\n",
    "        except IndexError:\n",
    "            dc = None\n",
    "        try:\n",
    "            dd = dt_pull_s[year+3] #4th\n",
    "        except IndexError:\n",
    "            dd = None\n",
    "\n",
    "        # Append Year\n",
    "        db_year.append(da)\n",
    "\n",
    "        # Append Pack\n",
    "        if re.search(p2,db):\n",
    "            pass\n",
    "        else:\n",
    "            db = erwo\n",
    "        db_pack.append(db)\n",
    "\n",
    "        # Append Rarity\n",
    "        if dd == None :\n",
    "            k = \"N\"\n",
    "        elif re.search(p1,dd):\n",
    "            k = \"N\"\n",
    "        \n",
    "        elif  len(dd) > len(dc): # Override 4th to 3rd\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dc\n",
    "        \n",
    "        else :\n",
    "            if len(dd) > 10: # For jp 8\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                if re.search(p1,dc):\n",
    "                    k = \"N\"\n",
    "                else:\n",
    "                    k = dd\n",
    "        db_rare.append(k)\n",
    "\n",
    "    k1 = []\n",
    "    k2 = []\n",
    "    k3 = []\n",
    "    k4 = []\n",
    "    numb2 = []\n",
    "    numb2.append(str(numb))\n",
    "    \n",
    "    k1.append(numb2)\n",
    "    k1.append(dt_name_all)\n",
    "    k1.append(db_pack)\n",
    "\n",
    "    k2.append(numb2)\n",
    "    k2.append(dt_name_all)\n",
    "    k2.append(db_rare)\n",
    "\n",
    "    k3.append(numb2)\n",
    "    k3.append(dt_name_all)\n",
    "    k3.append(db_stats)\n",
    "\n",
    "    k4.append(numb2)\n",
    "    k4.append(dt_name_all)\n",
    "    k4.append(db_year)\n",
    "\n",
    "    merged1 = list(itertools.chain.from_iterable(k1))\n",
    "    merged2 = list(itertools.chain.from_iterable(k2))\n",
    "    merged3 = list(itertools.chain.from_iterable(k3))\n",
    "    merged4 = list(itertools.chain.from_iterable(k4))\n",
    "\n",
    "    data1 = \"\\t\".join(merged1)\n",
    "    data2 = \"\\t\".join(merged2)\n",
    "    data3 = \"\\t\".join(merged3)\n",
    "    data4 = \"\\t\".join(merged4)\n",
    "\n",
    "    # numb2 = str(numb)\n",
    "    # data1 = '\\t'.join([numb2, dt_name_all, db_pack])\n",
    "    # data2 = '\\t'.join([numb2, dt_name_all, db_rare])\n",
    "    # data3 = '\\t'.join([numb2, dt_name_all] + db_stats)\n",
    "    # data4 = '\\t'.join([numb2, dt_name_all] + db_year)\n",
    "    \n",
    "    # append the data\n",
    "    nline1.append(data1)\n",
    "    nline2.append(data2)\n",
    "    nline3.append(data3)\n",
    "    nline4.append(data4)\n",
    "\n",
    "\n",
    "master = 'C:/ML_YGO/Output/'\n",
    "f1 = master + 'out_pa.txt'\n",
    "f2 = master + 'out_ra.txt'\n",
    "f3 = master + 'out_st.txt'\n",
    "f4 = master + 'out_yr.txt'\n",
    "\n",
    "with open(f1, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline1:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f2, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline2:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f3, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline3:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "with open(f4, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "os.startfile(f1)\n",
    "os.startfile(f2)\n",
    "os.startfile(f3)\n",
    "os.startfile(f4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_full_db = 'C:/ML_YGO/Data/rares.txt'\n",
    "df = pd.read_csv(dir_full_db, sep='\\t')\n",
    "# db_digit = np.asarray(df[\"Digit\"])\n",
    "# db_name_ko = np.asarray(df[\"Name_KO\"])\n",
    "# def fill_na_with_code(df):\n",
    "#     for col in df.columns:\n",
    "#         if col != 'Code' and df[col].isnull().any():\n",
    "#             df[col].fillna(df['Code'], inplace=True)\n",
    "#     return df\n",
    "# fill_na_with_code(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = pd.unique(df.values.ravel())\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "카드명 추출 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "English Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link3 = '&request_locale=ko'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "xpath_name_en = '//*[@id=\"cardname\"]/h1/span'\n",
    "\n",
    "for i in range(0,54):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "    driver.get(link4)\n",
    "\n",
    "    try:\n",
    "        id = driver.find_element(By.XPATH, xpath_name_en)\n",
    "        idt = id.text\n",
    "        k = str(link2)\n",
    "        kk = k + \" - \" + idt\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korean Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=ko'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name_ja = '//*[@id=\"cardname\"]/h1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "dt_name=dt_name.text\n",
    "print(dt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_pack = '//*[@id=\"update_list\"]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pack = driver.find_element(By.XPATH, xpath_pack)\n",
    "dt_pack = dt_pack.text\n",
    "print(dt_pack)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Japanese Name Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_f = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link_b = '&request_locale=ja'\n",
    "link = link_f + str(numb) + link_b\n",
    "driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name_ja = '//*[@id=\"cardname\"]/h1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_name = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "dt_name=dt_name.text\n",
    "print(dt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "for i in range(0,50):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "    driver.get(link4)\n",
    "\n",
    "    try:\n",
    "        id = driver.find_element(By.XPATH, xpath_name_ja)\n",
    "        idt = id.text\n",
    "        m = idt.split(\"\\n\")\n",
    "        m = \"\\t\".join(m)\n",
    "        k = str(link2)\n",
    "        kk = k + \"\\t\" + m\n",
    "        print(kk)\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid=12950&request_locale=ja'\n",
    "req = requests.get(home)\n",
    "req.text\n",
    "soup = BeautifulSoup(req.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = soup.find(\"div\", {\"id\": \"cardname\"}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = soup.find(\"div\", {\"id\": \"update_list\"}).text\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data.txt'\n",
    "with open(filename) as file:\n",
    "    lines = [line.rstrip() for line in file]\n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link1 = 'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid='\n",
    "link3 = '&request_locale=ja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline = []\n",
    "\n",
    "for i in range(0,100):\n",
    "    link2=lines[i]\n",
    "    link4 = link1+link2+link3\n",
    "\n",
    "    req = requests.get(link4)\n",
    "    req.text\n",
    "    soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "    try:\n",
    "        b = soup.find(\"div\", {\"id\": \"cardname\"}).text\n",
    "        b1= b.replace(\"\\n\",\"\")\n",
    "        b2= b1.replace(\"\\t\\t\",\"\\t\")\n",
    "        b3= b2.replace(\"\\t\\t\",\"\\t\")\n",
    "        b4 = b3.split(\"\\t\")\n",
    "        b5 = \"\\t\".join(b4)\n",
    "        k = str(link2)\n",
    "        kk = k + \"\\t\" + b5\n",
    "        # print(kk)\n",
    "        nline.append(kk)\n",
    "\n",
    "    except:\n",
    "        print(i)\n",
    "        print(link2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readme_jp.txt', 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline:\n",
    "        # write each item on a new line\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c50a568c9bb54733425ee4b50464281b54488c5e15ff27e4e32e073d46803f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
