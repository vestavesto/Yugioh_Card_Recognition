{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Install Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import re\n",
    "import itertools\n",
    "import os\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_db import load_db\n",
    "df = load_db(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 00 Global Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set general settings\n",
    "XPATH = \"xpath\"\n",
    "erwo = \"*Blank*\"\n",
    "dash = '-'\n",
    "slash = '/'\n",
    "cwd = Path.cwd()\n",
    "dir_main = Path.cwd().parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = re.compile('[0-9]{4}.[0-9]{2}.[0-9]{2}')\n",
    "p2 = re.compile(r'^[A-Z0-9]+(?:-[A-Z0-9]+)*$')\n",
    "\n",
    "rare = [\n",
    "    'CR',\n",
    "    'SE', 'EXSE', 'PSE',\n",
    "    'GUR', 'GSE', 'GR',\n",
    "    'HR','GH',\n",
    "    'UR (PR)','PGR',\n",
    "    'KC', 'KC+R','KC+UR',\n",
    "    'M', 'M+GR', 'M+SE', 'M+SR',\n",
    "    'N','R','SR',\n",
    "    'UR','UL',\n",
    "    'P','P+ES','P+EXSE','P+HR','P+R','PS','P+SE','P+SR','P+UR',\n",
    "    '20th SE', 'QCSE',\n",
    "    '10000 SE',\n",
    "    'SH','H','STAR','UR (Hobby)','ST', 'MR', 'PL',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpath_name = '//*[@id=\"cardname\"]/h1'\n",
    "xpath_pull = '//*[@id=\"update_list\"]'\n",
    "xpath_type = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[1]/span[2]'\n",
    "xpath_level = '//*[@id=\"CardTextSet\"]/div[1]/div[1]/div[2]/span[2]'\n",
    "xpath_atk = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[1]/span[2]'\n",
    "xpath_def = '//*[@id=\"CardTextSet\"]/div[1]/div[2]/div[2]/span[2]'\n",
    "xpath_spc = '//*[@id=\"CardTextSet\"]/div[1]/div[3]/div/p'\n",
    "xpath_year = '//*[@id=\"update_list\"]/div[2]/div/div/div[1]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sample\n",
    "db_code = np.asanyarray(df[\"Code\"])\n",
    "db_digit = np.asarray(df[\"Digit\"])\n",
    "db_name_ko = np.asarray(df[\"Name_KO\"])\n",
    "db_name_ja = np.asarray(df[\"Name_JA\"])\n",
    "db_name_en = np.asarray(df[\"Name_EN\"])\n",
    "db_type = np.asarray(df['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "56\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "string_lengths = np.char.str_len(db_name_ko.astype('str'))\n",
    "max_length = np.max(string_lengths)\n",
    "print(max_length)\n",
    "\n",
    "string_lengths = np.char.str_len(db_name_en.astype('str'))\n",
    "max_length = np.max(string_lengths)\n",
    "print(max_length)\n",
    "\n",
    "string_lengths = np.char.str_len(db_name_ja.astype('str'))\n",
    "max_length = np.max(string_lengths)\n",
    "print(max_length)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Run driver in headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create headless ChromeOptions object\n",
    "options = Options()\n",
    "options.add_argument('--headless')\n",
    "\n",
    "# Create a new ChromeDriverService object with the path to the Chromedriver executable\n",
    "service = Service('C://chromedriver.exe')\n",
    "\n",
    "# Initialize Chrome driver with headless options\n",
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 Check Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link (code, local):\n",
    "    link = f'https://www.db.yugioh-card.com/yugiohdb/card_search.action?ope=2&cid={code}&request_locale={local}'\n",
    "    driver.get(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ash Blossom & Joyous Spring\n"
     ]
    }
   ],
   "source": [
    "# Sample Card\n",
    "card_name = \"하루 우라라\"\n",
    "code =  db_code[np.where(db_name_ko == card_name)][0]\n",
    "local = 'en'\n",
    "get_link(code, local)\n",
    "\n",
    "# Get Name\n",
    "dt_name_all = driver.find_element(By.XPATH, xpath_name)\n",
    "dt_name_all=dt_name_all.text\n",
    "dt_name_all.split(\"\\n\")\n",
    "print(dt_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "하루 우라라\n",
      "Ash Blossom & Joyous Spring\n"
     ]
    }
   ],
   "source": [
    "# Sample Card\n",
    "card_name = \"하루 우라라\"\n",
    "code =  db_code[np.where(db_name_ko == card_name)][0]\n",
    "local = 'ko'\n",
    "get_link(code, local)\n",
    "\n",
    "# Get Name\n",
    "dt_name_all = driver.find_element(By.XPATH, xpath_name)\n",
    "dt_name_all=dt_name_all.text\n",
    "dt_name_all.split(\"\\n\")\n",
    "print(dt_name_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "はるうらら\n",
      "灰流うらら\n",
      "Ash Blossom & Joyous Spring\n"
     ]
    }
   ],
   "source": [
    "# Sample Card\n",
    "card_name = \"하루 우라라\"\n",
    "code =  db_code[np.where(db_name_ko == card_name)][0]\n",
    "local = 'ja'\n",
    "get_link(code, local)\n",
    "\n",
    "# Get Name\n",
    "dt_name_all = driver.find_element(By.XPATH, xpath_name)\n",
    "dt_name_all=dt_name_all.text\n",
    "dt_name_all.split(\"\\n\")\n",
    "print(dt_name_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Get Release Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Card\n",
    "card_name = \"하루 우라라\"\n",
    "code =  db_code[np.where(db_name_ko == card_name)][0]\n",
    "local = 'ko'\n",
    "get_link(code, local)\n",
    "\n",
    "#Get Release Info\n",
    "dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "dt_pull = dt_pull.text\n",
    "\n",
    "dt_pull_s = dt_pull.split(\"\\n\")\n",
    "dt_pull_s.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_year=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p1,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_year.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_pack=[]\n",
    "for i in range(len(dt_pull_s)):\n",
    "    dt_temp = dt_pull_s[i]\n",
    "    gen = re.search(p2,dt_temp)\n",
    "    if gen == None:\n",
    "        pass\n",
    "    else :\n",
    "        check_pack.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_capsule = []\n",
    "for year in check_year:\n",
    "    a = dt_pull_s[year]\n",
    "    try:\n",
    "        b = dt_pull_s[year+1]\n",
    "    except:\n",
    "        b = None\n",
    "    try:\n",
    "        c = dt_pull_s[year+2]\n",
    "    except:\n",
    "        c = None\n",
    "    try:\n",
    "        d = dt_pull_s[year+3]\n",
    "    except:\n",
    "        d = None\n",
    "    db_capsule.append([ a,b,c,d ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfv = pd.DataFrame (db_capsule, columns = [\"Year\",\"Code\",\"Pack\",\"Rarity\"])\n",
    "dfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "for item in check_year:\n",
    "    da = dt_pull_s[item]\n",
    "    try:\n",
    "        db = dt_pull_s[item+1]\n",
    "    except:\n",
    "        db = None\n",
    "    try:\n",
    "        dc = dt_pull_s[item+2]\n",
    "    except:\n",
    "        dc = None\n",
    "    try:\n",
    "        dd = dt_pull_s[item+3]\n",
    "    except:\n",
    "        dd = None\n",
    "    # Append Year\n",
    "    db_year.append(da)\n",
    "    # Append Pack\n",
    "    if db == None:\n",
    "        db = erwo\n",
    "    elif re.search(p2,db):\n",
    "        pass\n",
    "    else:\n",
    "        db = erwo\n",
    "    db_pack.append(db)\n",
    "    # Append Rarity\n",
    "    if dd == None :\n",
    "        k = \"N\"\n",
    "    elif re.search(p1,dd):\n",
    "        k = \"N\"\n",
    "    elif  len(dd) > len(dc):\n",
    "        if re.search(p1,dc):\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            k = dc\n",
    "    else :\n",
    "        if len(dd) > 8:\n",
    "            k = \"N\"\n",
    "        else:\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dd\n",
    "    db_rare.append(k)\n",
    "    # print(f\"Year : {da} | Pack : {db} | Rarity : {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"Year\": db_year, \"Code\": db_pack, \"Rarity\": db_rare}\n",
    "dfv =  pd.DataFrame(data)\n",
    "dfv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Run for all Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12175\n"
     ]
    }
   ],
   "source": [
    "code_list = np.unique(db_code).tolist()\n",
    "print(len(code_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_update_db = f'{dir_main}/data/update_code.txt'\n",
    "code_list = np.loadtxt(dir_update_db, dtype='str')\n",
    "code_list = [str(text) for text in code_list]\n",
    "print(len(code_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04860 |                こころがわり                | 2023-02-18 | RC04-JP051 |   UR    |\n",
      "05328 |                 ぞうえん                 | 2023-02-18 | RC04-JP052 |   SR    |\n",
      "05496 |           ようがんまじんラヴァ・ゴーレム            | 2023-02-18 | RC04-JP001 |   SR    |\n",
      "05530 |                めいすいり                 | 2023-02-18 | RC04-JP053 |   SR    |\n",
      "05914 |            きょうせいだっしゅつそうち             | 2023-02-18 | RC04-JP070 |   SR    |\n",
      "06845 |           サイバー・エンジェル－べんてん－           | 2023-02-18 | RC04-JP025 |   SR    |\n",
      "07568 |            ローンファイア・ブロッサム             | 2023-02-18 | RC04-JP002 |   SR    |\n",
      "07652 |               サモンリミッター               | 2023-02-18 | RC04-JP071 |   SR    |\n",
      "08090 |          エンシェント・フェアリー・ドラゴン           | 2023-02-18 | RC04-JP031 |   UR    |\n",
      "08352 |               かせきちょうさ                | 2023-02-18 | RC04-JP054 |   SR    |\n",
      "08885 |               ひょうけっかい                | 2023-02-18 | RC04-JP072 |   SR    |\n",
      "08933 |             エフェクト・ヴェーラー              | 2023-02-18 | RC04-JP003 |   SR    |\n",
      "09190 |            ヴィジョンヒーロー　ファリス            | 2023-02-18 | RC04-JP004 |   SR    |\n",
      "09455 |              ぞうしょくするジー               | 2023-02-18 | RC04-JP005 |   UR    |\n",
      "09702 |           まかいはつげんせゆきデスガイド            | 2023-02-18 | RC04-JP006 |   SR    |\n",
      "10544 |              まどうしょのしんぱん              | 2023-02-18 | RC04-JP055 |   SR    |\n",
      "10943 |             ダウナード・マジシャン              | 2023-02-18 | RC04-JP036 |   UR    |\n",
      "11243 |            アーティファクト－ロンギヌス            | 2023-02-18 | RC04-JP007 |   SR    |\n",
      "11313 |           マスクドヒーロー　ダーク・ロウ            | 2023-02-18 | RC04-JP026 |   SR    |\n",
      "11384 |              アーク・デクレアラー              | 2023-02-18 | RC04-JP032 |   SR    |\n",
      "11422 |             ゴーストリックのだてんし             | 2023-02-18 | RC04-JP037 |   SR    |\n",
      "11461 |      ギャラクシーアイズ　フルアーマー・フォトン・ドラゴン      | 2023-02-18 | RC04-JP038 |   SR    |\n",
      "11838 |          レッドアイズ・フレアメタルドラゴン           | 2023-02-18 | RC04-JP039 |   SR    |\n",
      "11878 |               キュウシンヌトス               | 2023-02-18 | RC04-JP027 |   UR    |\n",
      "11927 |         ラーのよくしんりゅう－スフィア・モード          | 2023-02-18 | RC04-JP008 |   UR    |\n",
      "12337 |              ぎしきのしたじゅんび              | 2023-02-18 | RC04-JP056 |   UR    |\n",
      "12465 |             ごうよくでどんよくなつぼ             | 2023-02-18 | RC04-JP057 |   SR    |\n",
      "12544 |          ナンバーズ１００　ヌメロン・ドラゴン          | 2023-02-18 | RC04-JP040 |   SR    |\n",
      "12668 |               じげんしょうへき               | 2023-02-18 | RC04-JP073 |   SR    |\n",
      "12870 |          プレデター・プランツドラゴスタペリア          | 2023-02-18 | RC04-JP028 |   SR    |\n",
      "12900 |              ハーピィのはねふぶき              | 2023-02-18 | RC04-JP074 |   SR    |\n",
      "12950 |                はるうらら                 | 2023-02-18 | RC04-JP009 |   UR    |\n",
      "12952 |             フェアリーテイル－カグヤ             | 2023-02-18 | RC04-JP010 |   UR    |\n",
      "13293 |               きっこうしょうぶ               | 2023-02-18 | RC04-JP075 |   SR    |\n",
      "13405 |             インスペクト・ボーダー              | 2023-02-18 | RC04-JP011 |   UR    |\n",
      "13454 |               ぬまちのドロゴン               | 2023-02-18 | RC04-JP029 |   SR    |\n",
      "13506 |           ひがんのくろてんし　ケルビーニ            | 2023-02-18 | RC04-JP043 |   UR    |\n",
      "13587 |                やしきわらし                | 2023-02-18 | RC04-JP012 |   SR    |\n",
      "13601 |             トロイメア・ユニコーン              | 2023-02-18 | RC04-JP044 |   UR    |\n",
      "13619 |              はかあなのしめいしゃ              | 2023-02-18 | RC04-JP058 |   UR    |\n",
      "13631 |               むげんほうよう                | 2023-02-18 | RC04-JP076 |   UR    |\n",
      "13691 |            マジカライズ・フュージョン             | 2023-02-18 | RC04-JP059 |   SR    |\n",
      "13853 |          ブラックフェザー－どくかぜのシムーン          | 2023-02-18 | RC04-JP013 |   SR    |\n",
      "13868 |              ジャンク・スピーダー              | 2023-02-18 | RC04-JP033 |   SR    |\n",
      "13981 |            みかいいきのジャッカロープ             | 2023-02-18 | RC04-JP014 |   SR    |\n",
      "14114 |          ヴァレルロード・サベージ・ドラゴン           | 2023-02-18 | RC04-JP034 |   SR    |\n",
      "14144 |             ごうよくできんまんなつぼ             | 2023-02-18 | RC04-JP060 |   SR    |\n",
      "14288 |           シーオルフェゴールディンギルス            | 2023-02-18 | RC04-JP041 |   SR    |\n",
      "14297 |         ジャックナイツ・パラディオンアストラム          | 2023-02-18 | RC04-JP045 |   SR    |\n",
      "14356 |             クロノダイバー・リダン              | 2023-02-18 | RC04-JP042 |   SR    |\n",
      "14542 |           コード・トーカー・インヴァート            | 2023-02-18 | RC04-JP046 |   SR    |\n",
      "14721 |             ストライカー・ドラゴン              | 2023-02-18 | RC04-JP047 |   SR    |\n",
      "14740 |            ディメンション・アトラクター            | 2023-02-18 | RC04-JP015 |   UR    |\n",
      "14741 |             げんしせいめいたいニビル             | 2023-02-18 | RC04-JP016 |   UR    |\n",
      "14742 |              めいおうけっかいは               | 2023-02-18 | RC04-JP061 |   SR    |\n",
      "14876 |             ライトニング・ストーム              | 2023-02-18 | RC04-JP062 |   UR    |\n",
      "14937 |            しんせいまこうごうセレーネ             | 2023-02-18 | RC04-JP048 |   SR    |\n",
      "14953 |            ディープ・オブ・ブルーアイズ            | 2023-02-18 | RC04-JP017 |   SR    |\n",
      "14959 |        ギャラクシーアイズ・アフターグロウ・ドラゴン        | 2023-02-18 | RC04-JP018 |   SR    |\n",
      "14962 |           デコード・トーカー・ヒートソウル           | 2023-02-18 | RC04-JP049 |   SR    |\n",
      "14969 |              ふうれいばいしウィン              | 2023-02-18 | RC04-JP019 |   SR    |\n",
      "15123 |            おうごんきょうエルドリッチ             | 2023-02-18 | RC04-JP020 |   UR    |\n",
      "15239 |            ドラグマのせいじょエクレシア            | 2023-02-18 | RC04-JP021 |   SR    |\n",
      "15245 |              アルバスのらくいん               | 2023-02-18 | RC04-JP022 |   SR    |\n",
      "15286 |               てんていのしと                | 2023-02-18 | RC04-JP063 |   SR    |\n",
      "15296 |               さんせんのさい                | 2023-02-18 | RC04-JP064 |   UR    |\n",
      "15299 |             きんじられたひとしずく              | 2023-02-18 | RC04-JP065 |   UR    |\n",
      "15304 |            ドラグマ・パニッシュメント             | 2023-02-18 | RC04-JP077 |   UR    |\n",
      "15310 |               シャドールーク                | 2023-02-18 | RC04-JP078 |   SR    |\n",
      "15313 |               てんろうせつごく               | 2023-02-18 | RC04-JP079 |   SR    |\n",
      "15332 |               ゴッド・スライム               | 2023-02-18 | RC04-JP030 |   SR    |\n",
      "15478 |              カオス・テリトリー               | 2023-02-18 | RC04-JP066 |   UR    |\n",
      "15502 |               ししおうアルファ               | 2023-02-18 | RC04-JP023 |   SR    |\n",
      "15549 |            トライブリゲード・リボルト             | 2023-02-18 | RC04-JP080 |   SR    |\n",
      "15619 |           マギストス・メイデンアルテミス            | 2023-02-18 | RC04-JP050 |   SR    |\n",
      "15756 |             きんまんでけんきょなつぼ             | 2023-02-18 | RC04-JP067 |   UR    |\n",
      "16198 |              あやめのそうけんし               | 2023-02-18 | RC04-JP024 |   SR    |\n",
      "16386 |             フルール・ド・バロネス              | 2023-02-18 | RC04-JP035 |   UR    |\n",
      "16555 |              スモール・ワールド               | 2023-02-18 | RC04-JP068 |   UR    |\n",
      "16654 |            マジシャンズ・サルベーション            | 2023-02-18 | RC04-JP069 |   SR    |\n"
     ]
    }
   ],
   "source": [
    "local = 'ja' # en, ja, ko\n",
    "\n",
    "nline0 = []\n",
    "nline1 = []\n",
    "nline2 = []\n",
    "nline3 = []\n",
    "nline4 = []\n",
    "\n",
    "\n",
    "run_s = 0\n",
    "run_e = len(code_list)\n",
    "\n",
    "for i in range(run_s, run_e):\n",
    "    code = int(code_list[i])\n",
    "    get_link(code, local)\n",
    "\n",
    "    try:\n",
    "        dt_name = driver.find_element(By.XPATH, xpath_name).text\n",
    "        if \"\\n\" in dt_name:\n",
    "            dt_name_sp = dt_name.split(\"\\n\")\n",
    "            if local == 'ja':\n",
    "                dt_name_all = [dt_name_sp[0], dt_name_sp[1]]\n",
    "            elif local == 'en':\n",
    "                dt_name_all = [dt_name_sp[0], '']\n",
    "            elif local == 'ko':\n",
    "                dt_name_all = [dt_name_sp[0], '']\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            if local == 'ja':\n",
    "                dt_name_all = [dt_name, erwo]\n",
    "            elif local == 'en':\n",
    "                dt_name_all = [dt_name, '']\n",
    "            elif local == 'ko':\n",
    "                dt_name_all = [dt_name, '']\n",
    "            else:\n",
    "                break\n",
    "    except:\n",
    "        dt_name_all = [erwo, erwo]\n",
    "\n",
    "\n",
    "    try:\n",
    "        dt_type = driver.find_element(By.XPATH, xpath_type).text\n",
    "    except:\n",
    "        dt_type = erwo\n",
    "\n",
    "    try:\n",
    "        dt_level = driver.find_element(By.XPATH, xpath_level).text\n",
    "    except:\n",
    "        dt_level = erwo\n",
    "    \n",
    "    try:\n",
    "        dt_atk = driver.find_element(By.XPATH, xpath_atk).text\n",
    "    except:\n",
    "        dt_atk = erwo\n",
    "\n",
    "    try:\n",
    "        dt_def = driver.find_element(By.XPATH, xpath_def).text\n",
    "    except:\n",
    "        dt_def = erwo\n",
    "\n",
    "    try:\n",
    "        dt_spc = driver.find_element(By.XPATH, xpath_spc).text\n",
    "    except:\n",
    "        dt_spc = erwo\n",
    "\n",
    "    db_stats = [dt_type, dt_level, dt_atk, dt_def, dt_spc]\n",
    "\n",
    "    try:\n",
    "        dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "        dt_pull = dt_pull.text\n",
    "    except:\n",
    "        dt_pull = erwo\n",
    "\n",
    "    dt_pull_s = dt_pull.split(\"\\n\")\n",
    "    dt_pull_s.pop(0)\n",
    "\n",
    "    check_year = [m for m, dt_temp in enumerate(dt_pull_s) if re.search(p1, dt_temp)]\n",
    "\n",
    "    db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "    # fill Normal to blank\n",
    "    for year in check_year:\n",
    "        da = dt_pull_s[year] #1st\n",
    "        try:\n",
    "            db = dt_pull_s[year+1] #2nd\n",
    "        except IndexError:\n",
    "            db = None\n",
    "        try:\n",
    "            dc = dt_pull_s[year+2] #3rd\n",
    "        except IndexError:\n",
    "            dc = None\n",
    "        try:\n",
    "            dd = dt_pull_s[year+3] #4th\n",
    "        except IndexError:\n",
    "            dd = None\n",
    "\n",
    "        # Append Year\n",
    "        db_year.append(da)\n",
    "\n",
    "        # Append Pack\n",
    "        if re.search(p2,db):\n",
    "            pass\n",
    "        else:\n",
    "            db = erwo\n",
    "        db_pack.append(db)\n",
    "\n",
    "        # Append Rarity\n",
    "        if dd == None :\n",
    "            k = \"N\"\n",
    "        elif re.search(p1,dd):\n",
    "            k = \"N\"\n",
    "        \n",
    "        elif  len(dd) > len(dc): # Override 4th to 3rd\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dc\n",
    "        \n",
    "        else :\n",
    "            if len(dd) > 10: # For jp 8\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                if re.search(p1,dc):\n",
    "                    k = \"N\"\n",
    "                else:\n",
    "                    k = dd\n",
    "        db_rare.append(k)\n",
    "\n",
    "    exp_name = []\n",
    "    exp_pack = []\n",
    "    exp_rare = []\n",
    "    exp_stat = []\n",
    "    exp_year = []\n",
    "\n",
    "    numb2 = []\n",
    "    numb2.append(str(code))\n",
    "    \n",
    "    exp_name.append(numb2)\n",
    "    exp_name.append(dt_name_all)\n",
    "\n",
    "    exp_pack.append(numb2)\n",
    "    exp_pack.append(db_pack)\n",
    "\n",
    "    exp_rare.append(numb2)\n",
    "    exp_rare.append(db_rare)\n",
    "\n",
    "    exp_stat.append(numb2)\n",
    "    exp_stat.append(db_stats)\n",
    "\n",
    "    exp_year.append(numb2)\n",
    "    exp_year.append(db_year)\n",
    "\n",
    "    merged0 = list(itertools.chain.from_iterable(exp_name))\n",
    "    merged1 = list(itertools.chain.from_iterable(exp_pack))\n",
    "    merged2 = list(itertools.chain.from_iterable(exp_rare))\n",
    "    merged3 = list(itertools.chain.from_iterable(exp_stat))\n",
    "    merged4 = list(itertools.chain.from_iterable(exp_year))\n",
    "\n",
    "    data0 = \"\\t\".join(merged0)\n",
    "    data1 = \"\\t\".join(merged1)\n",
    "    data2 = \"\\t\".join(merged2)\n",
    "    data3 = \"\\t\".join(merged3)\n",
    "    data4 = \"\\t\".join(merged4)\n",
    "\n",
    "    # append the data\n",
    "    nline0.append(data0)\n",
    "    nline1.append(data1)\n",
    "    nline2.append(data2)\n",
    "    nline3.append(data3)\n",
    "    nline4.append(data4)\n",
    "\n",
    "    try:\n",
    "        print(f'{code:05d} | {str(dt_name_all[0])[:36]:^36} | {db_year[0]} | {db_pack[0][:10]:^10} | {db_rare[0]:^7} |')\n",
    "\n",
    "    except:\n",
    "        print(f'{code:05d} | Error |')\n",
    "\n",
    "master = f'{dir_main}/Output/'\n",
    "f0 = master + 'out_nm.txt'\n",
    "f1 = master + 'out_pa.txt'\n",
    "f2 = master + 'out_ra.txt'\n",
    "f3 = master + 'out_st.txt'\n",
    "f4 = master + 'out_yr.txt'\n",
    "\n",
    "open(f0, 'w').close()\n",
    "with open(f0, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline0:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f1, 'w').close()\n",
    "with open(f1, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline1:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f2, 'w').close()\n",
    "with open(f2, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline2:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f3, 'w').close()\n",
    "with open(f3, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline3:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f4, 'w').close()\n",
    "with open(f4, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "os.startfile(f0)\n",
    "os.startfile(f1)\n",
    "os.startfile(f2)\n",
    "os.startfile(f3)\n",
    "os.startfile(f4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on Specified Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nline0 = []\n",
    "nline1 = []\n",
    "nline2 = []\n",
    "nline3 = []\n",
    "nline4 = []\n",
    "\n",
    "local = 'en' # en, ja, ko\n",
    "\n",
    "code_s = 18450\n",
    "code_e = 18461\n",
    "\n",
    "for code in range(code_s,code_e+1):\n",
    "    get_link(code, local)\n",
    "    try:\n",
    "        dt_name = driver.find_element(By.XPATH, xpath_name).text\n",
    "        if \"\\n\" in dt_name:\n",
    "            dt_name_sp = dt_name.split(\"\\n\")\n",
    "            if local == 'ja':\n",
    "                dt_name_all = [dt_name_sp[0], dt_name_sp[1]]\n",
    "            elif local == 'en':\n",
    "                dt_name_all = [dt_name_sp[0], '']\n",
    "            elif local == 'ko':\n",
    "                dt_name_all = [dt_name_sp[0], '']\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            if local == 'ja':\n",
    "                dt_name_all = [dt_name, erwo]\n",
    "            elif local == 'en':\n",
    "                dt_name_all = [dt_name, '']\n",
    "            elif local == 'ko':\n",
    "                dt_name_all = [dt_name, '']\n",
    "            else:\n",
    "                break\n",
    "    except:\n",
    "        dt_name_all = [erwo, erwo]\n",
    "\n",
    "\n",
    "    try:\n",
    "        dt_type = driver.find_element(By.XPATH, xpath_type).text\n",
    "    except:\n",
    "        dt_type = erwo\n",
    "\n",
    "    try:\n",
    "        dt_level = driver.find_element(By.XPATH, xpath_level).text\n",
    "    except:\n",
    "        dt_level = erwo\n",
    "    \n",
    "    try:\n",
    "        dt_atk = driver.find_element(By.XPATH, xpath_atk).text\n",
    "    except:\n",
    "        dt_atk = erwo\n",
    "\n",
    "    try:\n",
    "        dt_def = driver.find_element(By.XPATH, xpath_def).text\n",
    "    except:\n",
    "        dt_def = erwo\n",
    "\n",
    "    try:\n",
    "        dt_spc = driver.find_element(By.XPATH, xpath_spc).text\n",
    "    except:\n",
    "        dt_spc = erwo\n",
    "\n",
    "    db_stats = [dt_type, dt_level, dt_atk, dt_def, dt_spc]\n",
    "\n",
    "    try:\n",
    "        dt_pull = driver.find_element(By.XPATH, xpath_pull)\n",
    "        dt_pull = dt_pull.text\n",
    "    except:\n",
    "        dt_pull = erwo\n",
    "\n",
    "    dt_pull_s = dt_pull.split(\"\\n\")\n",
    "    dt_pull_s.pop(0)\n",
    "\n",
    "    check_year = [m for m, dt_temp in enumerate(dt_pull_s) if re.search(p1, dt_temp)]\n",
    "\n",
    "    db_year, db_pack, db_rare = [], [], []\n",
    "\n",
    "    # fill Normal to blank\n",
    "    for year in check_year:\n",
    "        da = dt_pull_s[year] #1st\n",
    "        try:\n",
    "            db = dt_pull_s[year+1] #2nd\n",
    "        except IndexError:\n",
    "            db = None\n",
    "        try:\n",
    "            dc = dt_pull_s[year+2] #3rd\n",
    "        except IndexError:\n",
    "            dc = None\n",
    "        try:\n",
    "            dd = dt_pull_s[year+3] #4th\n",
    "        except IndexError:\n",
    "            dd = None\n",
    "\n",
    "        # Append Year\n",
    "        db_year.append(da)\n",
    "\n",
    "        # Append Pack\n",
    "        if re.search(p2,db):\n",
    "            pass\n",
    "        else:\n",
    "            db = erwo\n",
    "        db_pack.append(db)\n",
    "\n",
    "        # Append Rarity\n",
    "        if dd == None :\n",
    "            k = \"N\"\n",
    "        elif re.search(p1,dd):\n",
    "            k = \"N\"\n",
    "        \n",
    "        elif  len(dd) > len(dc): # Override 4th to 3rd\n",
    "            if re.search(p1,dc):\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                k = dc\n",
    "        \n",
    "        else :\n",
    "            if len(dd) > 10: # For jp 8\n",
    "                k = \"N\"\n",
    "            else:\n",
    "                if re.search(p1,dc):\n",
    "                    k = \"N\"\n",
    "                else:\n",
    "                    k = dd\n",
    "        db_rare.append(k)\n",
    "\n",
    "    exp_name = []\n",
    "    exp_pack = []\n",
    "    exp_rare = []\n",
    "    exp_stat = []\n",
    "    exp_year = []\n",
    "\n",
    "    numb2 = []\n",
    "    numb2.append(str(code))\n",
    "    \n",
    "    exp_name.append(numb2)\n",
    "    exp_name.append(dt_name_all)\n",
    "\n",
    "    exp_pack.append(numb2)\n",
    "    exp_pack.append(db_pack)\n",
    "\n",
    "    exp_rare.append(numb2)\n",
    "    exp_rare.append(db_rare)\n",
    "\n",
    "    exp_stat.append(numb2)\n",
    "    exp_stat.append(db_stats)\n",
    "\n",
    "    exp_year.append(numb2)\n",
    "    exp_year.append(db_year)\n",
    "\n",
    "    merged0 = list(itertools.chain.from_iterable(exp_name))\n",
    "    merged1 = list(itertools.chain.from_iterable(exp_pack))\n",
    "    merged2 = list(itertools.chain.from_iterable(exp_rare))\n",
    "    merged3 = list(itertools.chain.from_iterable(exp_stat))\n",
    "    merged4 = list(itertools.chain.from_iterable(exp_year))\n",
    "\n",
    "    data0 = \"\\t\".join(merged0)\n",
    "    data1 = \"\\t\".join(merged1)\n",
    "    data2 = \"\\t\".join(merged2)\n",
    "    data3 = \"\\t\".join(merged3)\n",
    "    data4 = \"\\t\".join(merged4)\n",
    "\n",
    "    # append the data\n",
    "    nline0.append(data0)\n",
    "    nline1.append(data1)\n",
    "    nline2.append(data2)\n",
    "    nline3.append(data3)\n",
    "    nline4.append(data4)\n",
    "\n",
    "    try:\n",
    "        print(f'{code:05d} | {str(dt_name_all[0])[:36]:^36} | {db_year[0]} | {db_pack[0][:10]:^10} | {db_rare[0]:^7} |')\n",
    "    except:\n",
    "        print(f'{code:05d} | Error |')\n",
    "\n",
    "master = f'{dir_main}/Output/'\n",
    "f0 = master + 'out_nm.txt'\n",
    "f1 = master + 'out_pa.txt'\n",
    "f2 = master + 'out_ra.txt'\n",
    "f3 = master + 'out_st.txt'\n",
    "f4 = master + 'out_yr.txt'\n",
    "\n",
    "open(f0, 'w').close()\n",
    "with open(f0, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline0:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f1, 'w').close()\n",
    "with open(f1, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline1:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f2, 'w').close()\n",
    "with open(f2, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline2:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f3, 'w').close()\n",
    "with open(f3, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline3:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "open(f4, 'w').close()\n",
    "with open(f4, 'w', encoding=\"utf-8\") as fp:\n",
    "    for item in nline4:\n",
    "        fp.write(\"%s\\n\" % item)\n",
    "\n",
    "os.startfile(f0)\n",
    "os.startfile(f1)\n",
    "os.startfile(f2)\n",
    "os.startfile(f3)\n",
    "os.startfile(f4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c50a568c9bb54733425ee4b50464281b54488c5e15ff27e4e32e073d46803f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
